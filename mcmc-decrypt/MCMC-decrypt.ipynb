{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-06-02 15:28:15--  http://www.gutenberg.org/files/2600/2600-0.txt\n",
      "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
      "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3359545 (3.2M) [text/plain]\n",
      "Saving to: ‘2600-0.txt’\n",
      "\n",
      "2600-0.txt          100%[===================>]   3.20M  2.04MB/s    in 1.6s    \n",
      "\n",
      "2019-06-02 15:28:17 (2.04 MB/s) - ‘2600-0.txt’ saved [3359545/3359545]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget http://www.gutenberg.org/files/2600/2600-0.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# To make war and peace consistent with the text in the symbols file we have to \n",
    "# map certain unicode characters to their semantically identical ascii \n",
    "# equivalents \n",
    "\n",
    "# ” right quotes, U+201D\n",
    "# “ left quotes U+201C \n",
    "# both map to regular quotation marks : U+0022\n",
    "\n",
    "# ‘ left single quotation mark, U+2018\n",
    "# ’ right signle quotation mark, U+2019\n",
    "# both map to regular quotation mark: U+0027\n",
    "\n",
    "with open(\"2600-0.txt\") as train_file:\n",
    "    text = train_file.read()\n",
    "    text = re.sub('\\n|\\t','', text)\n",
    "    text = text.replace(\"”\", '\"').replace(\"“\",'\"').replace(\"‘\", \"'\").replace(\"’\", \"'\")\n",
    "    \n",
    "#loading allowed symbols\n",
    "with open(\"symbols.txt\") as symbol_file:\n",
    "    symbols = []\n",
    "    for line in symbol_file:\n",
    "        symbols.append(line[:-1]) # can't use strip as one character is white-space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter estimates\n",
    "\n",
    "$p(s_i)$: Treat this is an estimate of a categorical distribution such that a letter $s$ (one hot encoded vector) drawn from it \\begin{equation}\\bar{s} \\sim \\textbf{Cat}(\\bar{p}) \\end{equation} with $\\bar{p}$ a vector of category probabilities. The maximum likelihood estimate of $p$ given observed draws is $p_i = \\frac{c_i}{\\sum c_i} $ i.e. the count of category $i$ divided by the total count. In small data settings is is conventional to use a dirichelet prior to ensure, for example, that none of the probabilities are zero. Here, we have a very large training corpus and ignore this.\n",
    "\n",
    "For the case of calculating the conditional distributions $p(s_n | s_{n-1})$, we use the same model, but parameterise a different distribution for each $s_{n-1}$. Due due the limitation of data here, we use a dirichelet prior on p with $\\alpha_i =1 $. \\begin{equation}p_{ij} = \\frac{c_{ij} + 1}{\\sum_j c_{ij} + N}\\end{equation} with $N$ the number of unique characters and $c_{ij}$ the counts of letter $s_i$ following letter $s_j$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Table with letter frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "counts = Counter(text)\n",
    "counts = {s: counts[s] for s in symbols}\n",
    "count_total = sum(counts.values())\n",
    "p_i = np.array([i / count_total for s, i in counts.items() ])\n",
    "symbols = [s for s in counts.keys()]\n",
    "\n",
    "def generate_conditional_counts(text):\n",
    "    ## encode a 2 by 2 array such that p(s_i | s_{i-1}) = arr[i,j]\n",
    "    conditional_counts = np.ones([len(symbols), len(symbols)])\n",
    "    for i in range(1, len(text)):\n",
    "        if text[i] in symbols and text[i-1] in symbols:\n",
    "            conditional_counts[symbols.index(text[i]), symbols.index(text[i-1])]+=1    \n",
    "    \n",
    "    return conditional_counts / np.sum(conditional_counts, axis=0)\n",
    "\n",
    "p_ij = generate_conditional_counts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Letter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.010721e-01</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.295109e-02</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.002394e-02</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.246619e-07</td>\n",
       "      <td>]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.081635e-02</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.335040e-02</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.775169e-02</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.295319e-04</td>\n",
       "      <td>:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.110846e-02</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.191702e-02</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.246619e-07</td>\n",
       "      <td>[</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.624089e-02</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.876381e-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.243574e-03</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.017815e-03</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.293191e-02</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7.402292e-04</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.895376e-02</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.460037e-02</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.368471e-02</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.828528e-02</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.931966e-02</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.272675e-04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.719740e-02</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.719215e-02</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7.129446e-02</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.835149e-03</td>\n",
       "      <td>\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8.431795e-03</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6.118189e-02</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9.415196e-06</td>\n",
       "      <td>/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.947972e-05</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.204820e-03</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5.862453e-02</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>6.233509e-05</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.298648e-05</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>7.467225e-06</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>9.739858e-05</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>7.454238e-04</td>\n",
       "      <td>q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.008108e-02</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.678577e-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.168783e-05</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3.714133e-04</td>\n",
       "      <td>;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2.175235e-04</td>\n",
       "      <td>)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2.175235e-04</td>\n",
       "      <td>(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4.804997e-05</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.274623e-03</td>\n",
       "      <td>!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.850573e-05</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>7.356840e-04</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2.444055e-03</td>\n",
       "      <td>'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>6.493239e-07</td>\n",
       "      <td>=</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>5.944560e-04</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.266733e-02</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1.753174e-05</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Frequency Letter\n",
       "0   1.010721e-01      e\n",
       "1   1.295109e-02      ,\n",
       "2   1.002394e-02      .\n",
       "3   3.246619e-07      ]\n",
       "4   2.081635e-02      u\n",
       "5   5.335040e-02      i\n",
       "6   3.775169e-02      d\n",
       "7   3.295319e-04      :\n",
       "8   3.110846e-02      l\n",
       "9   5.191702e-02      s\n",
       "10  3.246619e-07      [\n",
       "11  1.624089e-02      g\n",
       "12  5.876381e-05      0\n",
       "13  6.243574e-03      k\n",
       "14  1.017815e-03      ?\n",
       "15  5.293191e-02      h\n",
       "16  7.402292e-04      z\n",
       "17  1.895376e-02      m\n",
       "18  1.460037e-02      y\n",
       "19  6.368471e-02      a\n",
       "20  1.828528e-02      w\n",
       "21  1.931966e-02      c\n",
       "22  1.272675e-04      1\n",
       "23  4.719740e-02      r\n",
       "24  1.719215e-02      f\n",
       "25  7.129446e-02      t\n",
       "26  5.835149e-03      \"\n",
       "27  8.431795e-03      v\n",
       "28  6.118189e-02      o\n",
       "29  9.415196e-06      /\n",
       "30  1.947972e-05      3\n",
       "31  1.204820e-03      x\n",
       "32  5.862453e-02      n\n",
       "33  6.233509e-05      8\n",
       "34  1.298648e-05      7\n",
       "35  7.467225e-06      4\n",
       "36  9.739858e-05      *\n",
       "37  7.454238e-04      q\n",
       "38  1.008108e-02      b\n",
       "39  1.678577e-01       \n",
       "40  1.168783e-05      9\n",
       "41  3.714133e-04      ;\n",
       "42  2.175235e-04      )\n",
       "43  2.175235e-04      (\n",
       "44  4.804997e-05      2\n",
       "45  1.274623e-03      !\n",
       "46  1.850573e-05      6\n",
       "47  7.356840e-04      j\n",
       "48  2.444055e-03      '\n",
       "49  6.493239e-07      =\n",
       "50  5.944560e-04      -\n",
       "51  1.266733e-02      p\n",
       "52  1.753174e-05      5"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict({\"Letter\": letter_types, \"Frequency\": p_i})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Are the latent variables independent?\n",
    "\n",
    "No, imagine at 2 letter alphabet $[0,1]$. Then $\\sigma(0) = 0 \\rightarrow \\sigma(1) = 1$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Joint probabilities\n",
    "\n",
    "\\begin{align}p(s_1, ... s_n , e_1 ... e_n | \\sigma) &= p(e_1 ... e_n | s_1, ... s_n, \\sigma) p(s_1, \\ ... s_n) \\\\&=\\prod_i\\delta_{\\sigma(s_i),e_i}p(s_1, \\ ... s_n)\\end{align}\n",
    "\n",
    "$\\delta_{ij}$ is the kroenecker delta\n",
    "\n",
    "Alternatively, let $\\alpha = \\sigma^{-1}$ then \n",
    "\\begin{align}p(s_1, ... s_n , e_1 ... e_n | \\alpha) &= p(\\alpha(e_1), \\ ... \\alpha(e_n))\\end{align}\n",
    "which is fine as $\\sigma$ is bijective\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Proposal and acceptance probabilities\n",
    "\n",
    "Imagine $s_1, ... s_n , e_1 ... e_n$, are vectors that are one hot encoded to give letters. $\\alpha$ is effectively an $n_\\textbf{letters} \\times n_\\textbf{letters}$ permutation matrix that maps the encrypted symbols back to decrypted. The propoal distribution amounts to applying a random permutation matrix to $\\alpha$ that swaps any 2 rows. Ths is a reversible operation, so the acceptance probability is \\begin{equation} min\\left(1, \\frac{p(\\alpha_m(e_1), \\ ... \\alpha_m(e_n)) }{ p(\\alpha_{m-1}(e_1), \\ ... \\alpha_{m-1}(e_n))}\\right) \\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Implementing the mh algorithm\n",
    "\n",
    "This is not a very general MH algorithm, and could use some re-factoring. It is implemented mostly using a numpy vectorized approach, although there is an indicated list comprehension that is likely to be wasteful. Future would could include making this more general and writing unit tests. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in my younger and more vulnerable years my fat*er gave me some advice t*at i've been turning over in my mind ever since. \"w*enever you feel like criticizing any one,\" *e told me, \"just remember t*at all t*e people in t*is world *aven't *ad t*e advantages t*at you've *ad.\" *e didn't say any more but we've always been unusually communicative in a reserved way, and i understood t*at *e meant a great deal more t*an t*at. in consequence i'm inclined to reserve all judgments, a *abit t*at *as opened up many curious natures to me and also made me t*e victim of not a few veteran bores. t*e abnormal mind is quick to detect and attac* itself to t*is quality w*en it appears in a normal person, and so it came about t*at in college i was unjustly accused of being a politician, because i was privy to t*e secret griefs of wild, unknown men. most of t*e confidences were unsoug*t--frequently i *ave feigned sleep, preoccupation, or a *ostile levity w*en i realized by some unmistakable sign t*at an intimate revelation was quivering on t*e *orizon--for t*e intimate revelations of young men or at least t*e terms in w*ic* t*ey express t*em are usually plagiaristic and marred by obvious suppressions. reserving judgments is a matter of infinite *ope. i am still a little afraid of missing somet*ing if i forget t*at, as my fat*er snobbis*ly suggested, and i snobbis*ly repeat a sense of t*e fundamental decencies is parcelled out unequally at birt*.\n"
     ]
    }
   ],
   "source": [
    "from operator import mul\n",
    "import random as rd\n",
    "\n",
    "with open(\"message.txt\") as message_file:\n",
    "    message_text = message_file.read().strip()\n",
    "\n",
    "def calculate_logp(message, p_i, p_ij):\n",
    "    \"\"\" Calculate the log probability of the message in one-hot format\n",
    "    \"\"\"\n",
    "    \n",
    "    letters = np.argmax(message,axis=1)\n",
    "    p_0 = np.log(p_i[letters[0]])\n",
    "    shifted_letters = np.roll(letters,1)[1:].reshape(len(message) - 1,1)\n",
    "    letters = letters[1:].reshape(len(message) - 1,1)\n",
    "    coords = np.concatenate([letters,shifted_letters], axis=1)\n",
    "    # Should really vectorize this too. I will if the algorithm is too slow.\n",
    "    res = np.sum(np.asarray([np.log(p_ij[li,li_m1]) for li, li_m1 in coords]))\n",
    "    \n",
    "    return res + p_0  \n",
    "\n",
    "def apply_row_permuation(m, ix_1, ix_2):\n",
    "    c = np.array(m[ix_1,:])\n",
    "    m[ix_1,:] = m[ix_2,:]\n",
    "    m[ix_2,:] = c\n",
    "    \n",
    "def one_hot_message(message):\n",
    "    message_conv = np.zeros((len(message), len(symbols)))\n",
    "    # one hot encode in the correct way\n",
    "    for ix, i in enumerate(message):\n",
    "        message_conv[ix, symbols.index(i)] = 1\n",
    "    assert np.sum(message_conv) == len(message)\n",
    "    return message_conv\n",
    "\n",
    "def encoded_to_str(message_conv):\n",
    "    return \"\".join([symbols[i] for i in np.argmax(message_conv,axis=1)])\n",
    "\n",
    "# in lieu of more rigorous unit tests..\n",
    "assert \"fdfvfdnjkefndvnkfneff849y589y3hernvjlidvdds*\" == encoded_to_str(one_hot_message(\"fdfvfdnjkefndvnkfneff849y589y3hernvjlidvdds*\"))\n",
    "\n",
    "def decode(message_conv, p_i, p_ij, n_iters=20000):\n",
    "    \n",
    "    a = np.eye(len(symbols)) # start with the identity mapping\n",
    "    rows_to_swap = rd.randint(0,len(symbols)-1), rd.randint(0,len(symbols)-1)\n",
    " \n",
    "\n",
    "    cur_log_p = -100000\n",
    "    for i in range(n_iters):\n",
    "        \n",
    "        decoded = message_conv.dot(a)\n",
    "        proposal_log_p = calculate_logp(decoded,p_i, p_ij)\n",
    "        \n",
    "        # update step\n",
    "        if proposal_log_p > cur_log_p or rd.uniform(0,1) < np.exp(proposal_log_p - cur_log_p):\n",
    "            cur_log_p = proposal_log_p\n",
    "        else: # put the permutation matrix back to how it was before\n",
    "            apply_row_permuation(a, rows_to_swap[0], rows_to_swap[1])\n",
    "        \n",
    "        # generate a new sample from the permutation distributions\n",
    "        rows_to_swap = rd.randint(0,len(symbols)-1), rd.randint(0,len(symbols)-1)\n",
    "        apply_row_permuation(a, rows_to_swap[0], rows_to_swap[1])\n",
    "\n",
    "        print (i,cur_log_p,end=\"\\r\")\n",
    "        \n",
    "    return a\n",
    "        \n",
    "        \n",
    "inv_transform = decode(one_hot_message(message_text), p_i, p_ij)\n",
    "decoded_message = encoded_to_str(one_hot_message(message_text).dot(inv_transform))\n",
    "\n",
    "print (decoded_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Text for posterity:\n",
    "\n",
    "in my younger and more vulnerable years my fat*er gave me some advice t*at i've been turning over in my mind ever since. \"w*enever you feel like criticizing any one,\" *e told me, \"just remember t*at all t*e people in t*is world *aven't *ad t*e advantages t*at you've *ad.\" *e didn't say any more but we've always been unusually communicative in a reserved way, and i understood t*at *e meant a great deal more t*an t*at. in consequence i'm inclined to reserve all judgments, a *abit t*at *as opened up many curious natures to me and also made me t*e victim of not a few veteran bores. t*e abnormal mind is quick to detect and attac* itself to t*is quality w*en it appears in a normal person, and so it came about t*at in college i was unjustly accused of being a politician, because i was privy to t*e secret griefs of wild, unknown men. most of t*e confidences were unsoug*t--frequently i *ave feigned sleep, preoccupation, or a *ostile levity w*en i realized by some unmistakable sign t*at an intimate revelation was quivering on t*e *orizon--for t*e intimate revelations of young men or at least t*e terms in w*ic* t*ey express t*em are usually plagiaristic and marred by obvious suppressions. reserving judgments is a matter of infinite *ope. i am still a little afraid of missing somet*ing if i forget t*at, as my fat*er snobbis*ly suggested, and i snobbis*ly repeat a sense of t*e fundamental decencies is parcelled out unequally at birt*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Ergodicity?\n",
    "\n",
    "A finite irreducible markov chain, meaning that there are nonzero transition probabilities between each state, generated by the MH algorithm is ergodic. Without the dirichelet prior, one could conceive of a local mode that yielded values of $p(s_n | s_{n-1}) = 0$ as this has never been observed in training data.\n",
    "\n",
    "Another issue is that by only swapping pairwise rows, there will be a large number of states that will have zero probability transitions. One could solve this by just trying out an entire new permutation at each step, though this is likely to be very slow to find optimal regions. A better approach might be to select from a distribution the number of rows of the permutation matrix to permute at each timestep, with larger values having low probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default-python3",
   "language": "python",
   "name": "default-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
